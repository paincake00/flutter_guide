
RAG (Retrieval-Augmented Generation) - это подход, при котором **LLM (например, GPT-4)** получает не только “свои знания” (те, что в параметрах модели), но и **внешние данные**, которые подтягиваются во время запроса.

#### flow:

1. Пользователь задаёт вопрос.
2. Система ищет релевантные документы (из базы знаний, векторного поиска, БД, API и т.п.).
3. Эти документы “подкладываются” в промпт (например, они получены из векторного хранилища).
4. LLM генерирует ответ, используя **как свои знания, так и внешние данные**.

### Как работает векторный поиск

1. **Текст → вектор**  
    Каждый документ (например, абзац из PDF или статья из базы знаний) прогоняется через **эмбеддинги**(embedding-модель), которые превращают текст в массив чисел (обычно размерностью 384, 768, 1536…).
    
    `"Как приготовить борщ?" → [0.12, -0.45, 0.98, ...]`
    
2. **Сохраняем в векторное хранилище**  
    Эти векторы кладём в векторную базу (например: ChromaDB, Pinecone, Weaviate, Milvus, Qdrant).
    
3. **Запрос пользователя → тоже вектор**  
    Когда пользователь спрашивает:
    
    `"Расскажи рецепт борща"`
    
    Этот запрос тоже преобразуется в вектор через ту же модель.
    
4. **Поиск ближайших векторов (nearest neighbors search)**  
    Алгоритм ищет, какие документы “ближе всего” в векторном пространстве (например, по косинусному сходству).  
    В итоге находятся те куски текста, которые **по смыслу ближе** к запросу.
    
5. **Подкладываем найденный текст в prompt для LLM**  
    LLM получает вопрос + найденные документы.  
    Она отвечает, опираясь на этот контекст.

### Agentic RAG

Агентная система сама управляет процессом рассуждений: может сама определять к каким источникам обращаться, может делать повторные запросы с новыми данными, пока не дойдет до удовлетворительного ответа.

![[Pasted image 20250914021459.png]]

- **Первоначальный вызов:** Цель пользователя (т.е. запрос пользователя) представляется LLM.
- **Использование инструментов:** Если модель обнаруживает недостающую информацию или неоднозначные инструкции, она выбирает инструмент или метод извлечения — например, запрос к векторной базе данных (например, Azure AI Search Hybrid search по частным данным) или структурированный SQL-запрос — чтобы собрать больше контекста.
- **Оценка и уточнение:** После анализа возвращенных данных модель решает, достаточно ли информации. Если нет, она уточняет запрос, пробует другой инструмент или корректирует подход.
- **Повтор до удовлетворения:** Этот цикл продолжается до тех пор, пока модель не решит, что у нее достаточно ясности и доказательств для предоставления окончательного, хорошо обоснованного ответа.
- **Память и состояние:** Поскольку система поддерживает состояние и память на протяжении шагов, она может вспоминать предыдущие попытки и их результаты, избегая повторяющихся циклов и принимая более обоснованные решения по мере продвижения.